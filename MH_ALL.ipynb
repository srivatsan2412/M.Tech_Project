{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "#######################################\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_Dataframes():\n",
    "    t1 = pd.read_csv('/Users/srivatsan/Sri/M.Tech_project/Multilevel_hierarchy_class/IDS2018/Data_O/F_18norm50_tr1')\n",
    "    df1 = pd.DataFrame(t1)\n",
    "    t2 = pd.read_csv('/Users/srivatsan/Sri/M.Tech_project/Multilevel_hierarchy_class/IDS2018/Data_O/F_18norm50_te1')\n",
    "    df2 = pd.DataFrame(t2)\n",
    "    \n",
    "    res = dict(); \n",
    "    res['df1']=df1\n",
    "    res['df2']=df2\n",
    "    \n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " def lv1_Replace(df,index):\n",
    "    df[index][df[index]!='Normal']='Attack'   \n",
    "  #  df[index] = df[index].replace({'DoS': 'Attack','Probe': 'Attack', 'R2L': 'Attack', 'U2R': 'Attack' })\n",
    "    return df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " def lv2_Replace(df,index):\n",
    "    df[index] = df[index].replace({'DoS':'G1', 'DDoS':'G1', 'BruteForce':'G2', 'Web':'G2', 'Infilteration':'G2', 'Bot':'G1'})\n",
    "    return df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_data(df_train,df_test,index):\n",
    " \n",
    "    df_data=df_train.iloc[:,0:index]\n",
    "    df_target=df_train.iloc[:,index]\n",
    "\n",
    "    df_data1=df_test.iloc[:,0:index]\n",
    "    df_target1=df_test.iloc[:,index]\n",
    "\n",
    "    traindata1 = np.array(df_data)\n",
    "    trainlabel1 = np.array(df_target)\n",
    "\n",
    "    testdata1 = np.array(df_data1)\n",
    "    testlabel1 = np.array(df_target1)\n",
    "    \n",
    "    res = dict(); \n",
    "    res['traindata']=traindata1\n",
    "    res['trainlabel']=trainlabel1\n",
    "    res['testdata']=testdata1\n",
    "    res['testlabel']=testlabel1\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_Accuracy(expected,predicted):\n",
    "    accuracy = accuracy_score(expected, predicted)\n",
    "    recall = recall_score(expected, predicted, average='micro')\n",
    "    precision = precision_score(expected, predicted , average='micro')\n",
    "    f1 = f1_score(expected, predicted , average='micro')\n",
    "    print(\"Accuracy\")\n",
    "    print(\"%.3f\" %accuracy)\n",
    "    print(\"precision\")\n",
    "    print(\"%.3f\" %precision)\n",
    "    print(\"recall\")\n",
    "    print(\"%.3f\" %recall)\n",
    "    print(\"f-score\")\n",
    "    print(\"%.3f\" %f1)\n",
    "    #     cm = metrics.confusion_matrix(expected, predicted)\n",
    "    #     print(cm)\n",
    "    #     tpr = float(cm[0][0])/np.sum(cm[0])\n",
    "    #     fpr = float(cm[1][1])/np.sum(cm[1])\n",
    "\n",
    "    #     print(\"fpr\")\n",
    "    #     print(\"%.3f\" %fpr)\n",
    "    #     print(\"tpr\")\n",
    "    #     print(\"%.3f\" %tpr)\n",
    "    #     print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_Accuracy(expected,predicted,gflag):\n",
    "        \n",
    "        if(gflag==1):\n",
    "            Labels=att_Grp1()\n",
    "        else:\n",
    "            Labels=att_Grp2()\n",
    "        \n",
    "        cm=metrics.multilabel_confusion_matrix(expected, predicted,labels=Labels)\n",
    "        \n",
    "        tn = cm[:, 0, 0]\n",
    "        tp = cm[:, 1, 1]\n",
    "        fn = cm[:, 1, 0]\n",
    "        fp = cm[:, 0, 1]\n",
    "        acc=(tp+tn)/(tp+tn+fp+fn)\n",
    "        prec=tp/(tp+fp)\n",
    "        rec=tp/(tp+fn)\n",
    "        f1= (2*tp)/(2*tp+fp+fn)\n",
    "        print(Labels)\n",
    "        df_res=pd.DataFrame()\n",
    "        df_res['Accuracy']=acc\n",
    "        df_res['Precision']=prec\n",
    "        df_res['Recall']=rec\n",
    "        df_res['Score']=f1\n",
    "        df_res=df_res.round(5)\n",
    "        if(gflag==1):\n",
    "            df_res.to_csv('/Users/srivatsan/Sri/M.Tech_project/Multilevel_hierarchy_class/Res_files/copy_paste_res1.csv',index=False)\n",
    "        else:\n",
    "            df_res.to_csv('/Users/srivatsan/Sri/M.Tech_project/Multilevel_hierarchy_class/Res_files/copy_paste_res2.csv',index=False)\n",
    "        \n",
    "        print(\"truepositive\")\n",
    "        print(tp)\n",
    "        sum1=sum(tp)\n",
    "        print(\"SUM TP\")\n",
    "        print(sum1)\n",
    "        \n",
    "        print(\"falsenegative\")\n",
    "        print(fn)\n",
    "        sum2=sum(fn)\n",
    "        print(\"SUM FN\")\n",
    "        print(sum2)\n",
    "        \n",
    "        print(\"Accuracy\")\n",
    "        print(acc)\n",
    "        print(\"Precision\")\n",
    "        print(prec)\n",
    "        print(\"Recall\")\n",
    "        print(rec)\n",
    "        print(\"F1_score\")\n",
    "        print(f1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_Accuracy(model,tra_data,tes_data,tra_label,tes_label,bflag,gflag):\n",
    "    t0=time.time()\n",
    "    model.fit(tra_data, tra_label)\n",
    "    print(\"training time:\", round(time.time()-t0, 3), \"s\")\n",
    "    print(model)\n",
    "    expected = tes_label\n",
    "    \n",
    "    t1=time.time()\n",
    "    predicted = model.predict(tes_data)\n",
    "    print(\"Testing time:\", round(time.time()-t1, 3), \"s\")\n",
    "    \n",
    "    \n",
    "    if(bflag==1):\n",
    "        bin_Accuracy(expected,predicted)\n",
    "    else:\n",
    "        multi_Accuracy(expected,predicted,gflag)\n",
    "    \n",
    "    return predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lv2_Preprocessing(dframe1,pre1,index):\n",
    "    #TestDataSet Preprocessing\n",
    "    df1=dframe1['df2'].copy(deep=True)\n",
    "    df1['target']=pre1\n",
    "    df_nor=df1[df1['target']=='Normal']\n",
    "    df_nor.to_csv('/Users/srivatsan/Sri/M.Tech_project/Multilevel_hierarchy_class/Comb_files/Att_Norm1.csv',index=False)\n",
    "    df_att=df1[df1['target']=='Attack']\n",
    "    df_att_nor=df_att[df_att[index]=='Normal']\n",
    "    df_att=df_att[df_att[index]!='Normal']\n",
    "    df_att_lv3=df_att.copy(deep=True)\n",
    "    df_att=lv2_Replace(df_att,index)\n",
    "    df_att_nor.to_csv('/Users/srivatsan/Sri/M.Tech_project/Multilevel_hierarchy_class/Comb_files/Nor_Att1.csv',index=False)\n",
    "    del df_att['target']\n",
    "    \n",
    "    #TrainDataSet Preprocessing\n",
    "    df_l2_tra=dframe1['df1'].copy(deep=True)\n",
    "    df_l2_tra=df_l2_tra[df_l2_tra[index]!='Normal']\n",
    "    df_l2_tra=lv2_Replace(df_l2_tra,index)      \n",
    "    \n",
    "    #Store the results and return\n",
    "    res=dict()\n",
    "    \n",
    "    res['df_att_lv3']=df_att_lv3\n",
    "    res['df_l2_tes']=df_att\n",
    "    res['df_l2_tra']=df_l2_tra\n",
    "    \n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def att_Grp1():\n",
    "    list1=['DoS','DDoS','Bot']\n",
    "    return list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def att_Grp2():\n",
    "    list2=[ 'BruteForce','Infilteration','Web']\n",
    "    return list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lv3_Preprocessing(dframe1,dframe2,pre2,index):\n",
    "    #Testdataset\n",
    "    df1=dframe2['df_att_lv3'].copy(deep=True)\n",
    "    df1['target1']=pre2\n",
    "    df_g1=df1[df1['target1']=='G1']\n",
    "    df_g2=df1[df1['target1']=='G2']\n",
    "    del df_g1['target1']\n",
    "    del df_g2['target1']\n",
    "    \n",
    "    l1=att_Grp1()\n",
    "    l2=att_Grp2()\n",
    "    \n",
    "    \n",
    "    df_g1_g2=df_g1[df_g1[index].isin(l2)]\n",
    "   # df_g1=df_g1[df_g1[index].isin(l1)]\n",
    "    \n",
    "    df_g2_g1=df_g2[df_g2[index].isin(l1)]\n",
    "   # df_g2=df_g2[df_g2[index].isin(l2)]\n",
    "    \n",
    "    df_g1_g2.to_csv('/Users/srivatsan/Sri/M.Tech_project/Multilevel_hierarchy_class/Comb_files/g1_g2.csv',index=False)\n",
    "    df_g2_g1.to_csv('/Users/srivatsan/Sri/M.Tech_project/Multilevel_hierarchy_class/Comb_files/g2_g1.csv',index=False)\n",
    "    \n",
    "    #TrainDataSet Preprocessing\n",
    "    df_l3_tra=dframe1['df1'].copy(deep=True)\n",
    "    df_l3_tra=df_l3_tra[df_l3_tra[index]!='Normal']\n",
    "    df_l3_tra_g1=df_l3_tra[df_l3_tra[index].isin(l1)]\n",
    "    df_l3_tra_g2=df_l3_tra[df_l3_tra[index].isin(l2)]\n",
    "    \n",
    "    #Store the results and return\n",
    "    res=dict() \n",
    "    \n",
    "    res['df_l3_g1_tes']=df_g1\n",
    "    res['df_l3_g1_tra']=df_l3_tra_g1\n",
    "    \n",
    "    res['df_l3_g2_tes']=df_g2\n",
    "    res['df_l3_g2_tra']=df_l3_tra_g2\n",
    "    \n",
    "    \n",
    "    return res\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_Accuracy(dframe3,pre3,pre4,index):\n",
    "    d1 = pd.read_csv('/Users/srivatsan/Sri/M.Tech_project/Multilevel_hierarchy_class/Comb_files/Att_Norm1.csv')\n",
    "    df_att_nor1 = pd.DataFrame(d1)\n",
    "    d2 = pd.read_csv('/Users/srivatsan/Sri/M.Tech_project/Multilevel_hierarchy_class/Comb_files/Nor_Att1.csv')\n",
    "    df_nor_att1 = pd.DataFrame(d2)\n",
    "    d3 = pd.read_csv('/Users/srivatsan/Sri/M.Tech_project/Multilevel_hierarchy_class/Comb_files/g2_g1.csv')\n",
    "    dff_g2_g1 = pd.DataFrame(d3)\n",
    "    d4 = pd.read_csv('/Users/srivatsan/Sri/M.Tech_project/Multilevel_hierarchy_class/Comb_files/g1_g2.csv')\n",
    "    dff_g1_g2 = pd.DataFrame(d4)\n",
    "    d5_g1=dframe3['df_l3_g1_tes']\n",
    "    d5_g1['target2']=pre3\n",
    "    del d5_g1['target']\n",
    "    d6_g2=dframe3['df_l3_g2_tes']\n",
    "    d6_g2['target2']=pre4\n",
    "    del d6_g2['target']\n",
    "    \n",
    "    list_a=list(df_att_nor1[index])\n",
    "    list_b=list(df_nor_att1[index])\n",
    "    list_a=list_a+list_b\n",
    "    list_b=list(dff_g2_g1[index])\n",
    "    list_a+=list_b\n",
    "    list_b=list(dff_g1_g2[index])\n",
    "    list_a+=list_b\n",
    "    list_b=list(d5_g1[index])\n",
    "    list_a+=list_b\n",
    "    list_b=list(d6_g2[index])\n",
    "    list_a+=list_b\n",
    "   \n",
    "    list_a1=list(df_att_nor1['target'])\n",
    "    list_b=list(df_nor_att1['target'])\n",
    "    list_a1=list_a1+list_b\n",
    "    list_b=list(dff_g2_g1['target'])\n",
    "    list_a1+=list_b\n",
    "    list_b=list(dff_g1_g2['target'])\n",
    "    list_a1+=list_b\n",
    "    list_b=list(d5_g1['target2'])\n",
    "    list_a1+=list_b\n",
    "    list_b=list(d6_g2['target2'])\n",
    "    list_a1+=list_b\n",
    "    \n",
    "    df_res1=pd.DataFrame()\n",
    "    df_res1['Exp']=list_a\n",
    "    df_res1['Pre']=list_a1\n",
    "    \n",
    "    exp1=np.array(df_res1['Exp'])\n",
    "    pre1=np.array(df_res1['Pre'])\n",
    "    \n",
    "    \n",
    "    accuracy = accuracy_score(exp1, pre1)\n",
    "    recall = recall_score(exp1, pre1, average='micro')\n",
    "    precision = precision_score(exp1, pre1 , average='micro')\n",
    "    f1 = f1_score(exp1, pre1 , average='micro')\n",
    "    \n",
    "    print(\"#########\")\n",
    "    print(\"Total Hierarchical F1_score\")\n",
    "    print(round(f1,5))\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MH_Model2(model2,dframe1,index1,index_str):\n",
    "    dframe2=lv2_Preprocessing(dframe1,dframe1['pre1'],index_str)\n",
    "    df3 = dframe2['df_l2_tra'].copy(deep=True)\n",
    "    df4 = dframe2['df_l2_tes'].copy(deep=True)\n",
    "    ttd2=train_test_data(df3,df4,index1)\n",
    "    print(\"Level_2 Accuracy\")\n",
    "    pre2=model_Accuracy(model2,ttd2['traindata'],ttd2['testdata'],ttd2['trainlabel'],ttd2['testlabel'],1,0)\n",
    "    dframe2['pre2']=pre2\n",
    "    \n",
    "    print(\"################\")\n",
    "     \n",
    "    return dframe2\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MH_Model3(model_3_1,model_3_2,dframe1,dframe2,index1,index_str):\n",
    "    dframe3=lv3_Preprocessing(dframe1,dframe2,dframe2['pre2'],index_str)\n",
    "    df5 = dframe3['df_l3_g1_tra'].copy(deep=True)\n",
    "    df6 = dframe3['df_l3_g1_tes'].copy(deep=True)\n",
    "    ttd3=train_test_data(df5,df6,index1)\n",
    "    \n",
    "    print(\"Level_3_G1 Accuracy\")\n",
    "    pre3=model_Accuracy(model_3_1,ttd3['traindata'],ttd3['testdata'],ttd3['trainlabel'],ttd3['testlabel'],0,1)\n",
    "    \n",
    "    print(\"################\")\n",
    "    \n",
    "    df7 = dframe3['df_l3_g2_tra'].copy(deep=True)\n",
    "    df8 = dframe3['df_l3_g2_tes'].copy(deep=True)\n",
    "    ttd3=train_test_data(df7,df8,index1)\n",
    "    \n",
    "    print(\"Level_3_G2 Accuracy\")\n",
    "    pre4=model_Accuracy(model_3_2,ttd3['traindata'],ttd3['testdata'],ttd3['trainlabel'],ttd3['testlabel'],0,2)\n",
    "    \n",
    "    total_Accuracy(dframe3,pre3,pre4,index_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MH_Model1(model1,index1,index_str):\n",
    "    time1=time.time()\n",
    "    dframe1=build_Dataframes()\n",
    "    \n",
    "    df1 = dframe1['df1'].copy(deep=True)\n",
    "    df2 = dframe1['df2'].copy(deep=True)\n",
    "    df1=lv1_Replace(df1,index_str)\n",
    "    df2=lv1_Replace(df2,index_str)\n",
    "    ttd1=train_test_data(df1,df2,index1)\n",
    "    print(\"Level_1 Accuracy\")\n",
    "    pre1=model_Accuracy(model1,ttd1['traindata'],ttd1['testdata'],ttd1['trainlabel'],ttd1['testlabel'],1,0)\n",
    "    dframe1['pre1']=pre1\n",
    "    print(\"################\")\n",
    "    \n",
    "    return dframe1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = KNeighborsClassifier()\n",
    "model2 = DecisionTreeClassifier()\n",
    "model3 = RandomForestClassifier()\n",
    "\n",
    "model5 = MLPClassifier(hidden_layer_sizes=(100,100,50), max_iter=100,activation = 'relu',solver='adam',random_state=1)\n",
    "model6 = LogisticRegression(tol=0.1,solver='lbfgs',multi_class='multinomial')\n",
    "model7 = AdaBoostClassifier(n_estimators=100, random_state=1)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MH_AllModel(model1,model2,model3,index1,index2):\n",
    "    dframe_1=MH_Model1(model1,index1,index2)\n",
    "    dframe_2=MH_Model2(model2,dframe_1,index1,index2)\n",
    "    MH_Model3(model3,dframe_1,dframe_2,index1,index_str)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/srivatsan/Sri/Anacond_Python/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level_1 Accuracy\n",
      "training time: 27.753 s\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')\n",
      "Testing time: 0.135 s\n",
      "Accuracy\n",
      "1.000\n",
      "precision\n",
      "1.000\n",
      "recall\n",
      "1.000\n",
      "f-score\n",
      "1.000\n",
      "################\n"
     ]
    }
   ],
   "source": [
    "dframe_1=MH_Model1(model2,78,'78')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level_2 Accuracy\n",
      "training time: 15.449 s\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "Testing time: 0.178 s\n",
      "Accuracy\n",
      "1.000\n",
      "precision\n",
      "1.000\n",
      "recall\n",
      "1.000\n",
      "f-score\n",
      "1.000\n",
      "################\n"
     ]
    }
   ],
   "source": [
    "dframe_2=MH_Model2(model3,dframe_1,78,'78')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level_3_G1 Accuracy\n",
      "training time: 2.45 s\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')\n",
      "Testing time: 0.029 s\n",
      "['DoS', 'DDoS', 'Bot']\n",
      "truepositive\n",
      "[40000 39987 39996]\n",
      "SUM TP\n",
      "119983\n",
      "falsenegative\n",
      "[0 0 0]\n",
      "SUM FN\n",
      "0\n",
      "Accuracy\n",
      "[1.         0.99980834 1.        ]\n",
      "Precision\n",
      "[1.         0.99942514 1.        ]\n",
      "Recall\n",
      "[1. 1. 1.]\n",
      "F1_score\n",
      "[1.         0.99971249 1.        ]\n",
      "################\n",
      "Level_3_G2 Accuracy\n",
      "training time: 121.152 s\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "Testing time: 172.334 s\n",
      "['BruteForce', 'Infilteration', 'Web']\n",
      "truepositive\n",
      "[22045 31930   193]\n",
      "SUM TP\n",
      "54168\n",
      "falsenegative\n",
      "[17955     4    12]\n",
      "SUM FN\n",
      "17971\n",
      "Accuracy\n",
      "[0.75116414 0.7509424  0.99954266]\n",
      "Precision\n",
      "[1.         0.63991823 0.90186916]\n",
      "Recall\n",
      "[0.551125   0.99987474 0.94146341]\n",
      "F1_score\n",
      "[0.71061326 0.78038885 0.92124105]\n",
      "#########\n",
      "Total Hierarchical F1_score\n",
      "0.94874\n"
     ]
    }
   ],
   "source": [
    "MH_Model3(model2,model1,dframe_1,dframe_2,78,'78')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
